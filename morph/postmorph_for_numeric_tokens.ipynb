{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from estnltk.vabamorf.morf import synthesize, analyze\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postmorph analysis for numeric tokens\n",
    "\n",
    "## Create a rules file for analyzing numeric tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9744 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>suffix</th>\n",
       "      <th>pos</th>\n",
       "      <th>form</th>\n",
       "      <th>ending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>teta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>neteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>lt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>neilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     number  suffix pos    form ending\n",
       "4838  ([1-9][0-9]*)?1[1-9]$           N       ?      0\n",
       "4959  ([1-9][0-9]*)?1[1-9]$    teta   N   pl ab   teta\n",
       "4999  ([1-9][0-9]*)?1[1-9]$     eta   N   pl ab   teta\n",
       "5041  ([1-9][0-9]*)?1[1-9]$      ta   N   pl ab   teta\n",
       "5087  ([1-9][0-9]*)?1[1-9]$  neteta   N   pl ab   teta\n",
       "5112  ([1-9][0-9]*)?1[1-9]$   eteta   N   pl ab   teta\n",
       "5151  ([1-9][0-9]*)?1[1-9]$       a   N   pl ab   teta\n",
       "4916  ([1-9][0-9]*)?1[1-9]$     ilt   N  pl abl    ilt\n",
       "4981  ([1-9][0-9]*)?1[1-9]$      lt   N  pl abl    ilt\n",
       "5039  ([1-9][0-9]*)?1[1-9]$   neilt   N  pl abl    ilt"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_words = {\n",
    "                '0$':                                  {'words': ('null', 'nullis'),\n",
    "                                                        'roots': ('null',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))1$':      {'words': ('üks', 'esimene'),\n",
    "                                                        'roots': ('üh', 'esime')},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))2$':      {'words': ('kaks', 'teine'),\n",
    "                                                        'roots': ('kah', 'tei')},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))3$':      {'words': ('kolm', 'kolmas'),\n",
    "                                                        'roots': ('kolm',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))4$':      {'words': ('neli', 'neljas'),\n",
    "                                                        'roots': ('nel',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))5$':      {'words': ('viis', 'viies'),\n",
    "                                                        'roots': ('vii',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))6$':      {'words': ('kuus', 'kuues'),\n",
    "                                                        'roots': ('kuu',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))7$':      {'words': ('seitse', 'seitsmes'),\n",
    "                                                        'roots': ('seits',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))8$':      {'words': ('kaheksa', 'kaheksas'),\n",
    "                                                        'roots': ('kaheks',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))9$':      {'words': ('üheksa', 'üheksas'),\n",
    "                                                        'roots': ('üheks',)},\n",
    "                '([1-9][0-9]*)?1[1-9]$':               {'words': ('kolmteist', 'kolmeteistkümnes'),\n",
    "                                                        'roots': ('kolmeteistküm',)},\n",
    "                '([1-9][0-9]*)?[1-9]0$':               {'words': ('kolmkümmend', 'kolmekümnes'),\n",
    "                                                        'roots': ('kolmeküm',)},\n",
    "                '([1-9][0-9]*)?[1-9]00$':              {'words': ('sada', 'sajas'),\n",
    "                                                        'roots': ('sad', 'sa')},\n",
    "                '([1-9][0-9]*)?[1-9]0{3,5}$':          {'words': ('tuhat', 'tuhandes'),\n",
    "                                                        'roots': ('tuha',)},\n",
    "                '([1-9][0-9]*)?[1-9]0{6,8}(0{6}0*)?$': {'words': ('miljon', 'miljones'),\n",
    "                                                        'roots': ('miljon',)},\n",
    "                '([1-9][0-9]*)?[1-9]0{9,11}$':         {'words': ('miljard', 'miljardes'),\n",
    "                                                        'roots': ('miljard',)}\n",
    "               }\n",
    "\n",
    "ordinal_number_words = {\n",
    "                '0\\.$':                                  {'words': ('nullis',),\n",
    "                                                          'roots': ('null',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))1\\.$':      {'words': ('esimene',),\n",
    "                                                          'roots': ('esime',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))2\\.$':      {'words': ('teine',),\n",
    "                                                          'roots': ('tei',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))3\\.$':      {'words': ('kolmas',),\n",
    "                                                          'roots': ('kolma',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))4\\.$':      {'words': ('neljas',),\n",
    "                                                          'roots': ('nel',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))5\\.$':      {'words': ('viies',),\n",
    "                                                          'roots': ('vii',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))6\\.$':      {'words': ('kuues',),\n",
    "                                                          'roots': ('kuu',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))7\\.$':      {'words': ('seitsmes',),\n",
    "                                                          'roots': ('seits',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))8\\.$':      {'words': ('kaheksas',),\n",
    "                                                          'roots': ('kaheks',)},\n",
    "                '(|[2-9]|([1-9][0-9]*[02-9]))9\\.$':      {'words': ('üheksas',),\n",
    "                                                          'roots': ('üheks',)},\n",
    "                '([1-9][0-9]*)?1[1-9]\\.$':               {'words': ('kolmeteistkümnes',),\n",
    "                                                          'roots': ('kolmeteistküm',)},\n",
    "                '([1-9][0-9]*)?[1-9]0\\.$':               {'words': ('kolmekümnes',),\n",
    "                                                          'roots': ('kolmeküm',)},\n",
    "                '([1-9][0-9]*)?[1-9]00\\.$':              {'words': ('sajas',),\n",
    "                                                          'roots': ('saja',)},\n",
    "                '([1-9][0-9]*)?[1-9]0{3,5}\\.$':          {'words': ('tuhandes',),\n",
    "                                                          'roots': ('tuhan',)},\n",
    "                '([1-9][0-9]*)?[1-9]0{6,8}(0{6}0*)?\\.$': {'words': ('miljones',),\n",
    "                                                          'roots': ('miljon',)},\n",
    "                '([1-9][0-9]*)?[1-9]0{9,11}\\.$':         {'words': ('miljardes',),\n",
    "                                                          'roots': ('miljard',)}\n",
    "               }\n",
    "\n",
    "\n",
    "\n",
    "forms =  ['sg n', 'pl n', 'sg g', 'pl g', 'sg p', 'pl p', 'sg ill', 'pl ill', 'adt', 'sg in', 'pl in',\n",
    "          'sg el', 'pl el', 'sg all', 'pl all', 'sg ad', 'pl ad', 'sg abl', 'pl abl', 'sg tr',\n",
    "          'pl tr', 'sg ter', 'pl ter', 'sg es', 'pl es', 'sg ab', 'pl ab', 'sg kom', 'pl kom']\n",
    "\n",
    "# all numbers\n",
    "for number, data in number_words.items():\n",
    "    data['analyses'] = {}\n",
    "    for form in forms:\n",
    "        for number_word in data['words']:\n",
    "            for synt in synthesize(number_word, form):\n",
    "                analysis = analyze([synt], disambiguate=False, guess=False, propername=False)[0]['analysis']\n",
    "                for a in analysis:\n",
    "                    if a['partofspeech'] in {'N', 'O'}:\n",
    "                        data['analyses'].setdefault(synt, set()).add((a['partofspeech'], a['form'], a['ending']))\n",
    "\n",
    "for number, data in number_words.items():\n",
    "    data['suffixes'] = {}\n",
    "    for word_form in data['analyses']:\n",
    "        for root in data['roots']:\n",
    "            ending = word_form.partition(root)[-1]\n",
    "            if ending:\n",
    "                for i in range(len(ending)):\n",
    "                    data['suffixes'][ending[i:]] = set()\n",
    "                break\n",
    "    for ending, analyses in data['suffixes'].items():\n",
    "        for word_form, a in data['analyses'].items():\n",
    "            if word_form.endswith(ending):\n",
    "                for pos, form, suffix in a:\n",
    "                    if pos!='N' or form!='sg n':\n",
    "                        analyses.add((pos, form, suffix))\n",
    "    data['suffixes'][''] = {('N', '?', '0')}\n",
    "\n",
    "table = []\n",
    "for number, data in number_words.items():\n",
    "    for ending, analyses in data['suffixes'].items():\n",
    "        for pos, form, normal_ending in analyses:\n",
    "            table.append({\n",
    "                        'number': number,\n",
    "                        'suffix': ending,\n",
    "                        'pos': pos,\n",
    "                        'form': form,\n",
    "                        'ending': normal_ending\n",
    "            })\n",
    "\n",
    "# ordinal numbers only\n",
    "for number, data in ordinal_number_words.items():\n",
    "    data['analyses'] = {}\n",
    "    for form in forms:\n",
    "        for number_word in data['words']:\n",
    "            for synt in synthesize(number_word, form):\n",
    "                analysis = analyze([synt], disambiguate=False, guess=False, propername=False)[0]['analysis']\n",
    "                for a in analysis:\n",
    "                    if a['partofspeech'] in {'O'}:\n",
    "                        data['analyses'].setdefault(synt, set()).add((a['partofspeech'], a['form'], a['ending']))\n",
    "\n",
    "for number, data in ordinal_number_words.items():\n",
    "    data['suffixes'] = {}\n",
    "    for word_form in data['analyses']:\n",
    "        for root in data['roots']:\n",
    "            ending = word_form.partition(root)[-1]\n",
    "            if ending:\n",
    "                for i in range(len(ending)):\n",
    "                    data['suffixes'][ending[i:]] = set()\n",
    "                break\n",
    "    for ending, analyses in data['suffixes'].items():\n",
    "        for word_form, a in data['analyses'].items():\n",
    "            if word_form.endswith(ending):\n",
    "                for pos, form, suffix in a:\n",
    "                    if pos!='O' or form!='sg n':\n",
    "                        analyses.add((pos, form, suffix))\n",
    "    data['suffixes'][''] = {('O', '?', '0')}\n",
    "\n",
    "\n",
    "for number, data in ordinal_number_words.items():\n",
    "    for ending, analyses in data['suffixes'].items():\n",
    "        for pos, form, normal_ending in analyses:\n",
    "            table.append({\n",
    "                        'number': number,\n",
    "                        'suffix': ending,\n",
    "                        'pos': pos,\n",
    "                        'form': form,\n",
    "                        'ending': normal_ending\n",
    "            })\n",
    "            \n",
    "            \n",
    "df = DataFrame.from_records(table, columns=['number', 'suffix', 'pos', 'form', 'ending'])\n",
    "df = df.sort_values(['number', 'pos', 'form', 'ending'])\n",
    "\n",
    "df.to_csv('results/number_analysis_rules.csv', index=False)\n",
    "\n",
    "print(len(df), 'lines')\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rules file [results/number_analysis_rules.csv](results/number_analysis_rules.csv) **pos**, **form** and **ending** cells contain the morphological analysis for the tokens that match **number** with **suffix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the rules from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_number_analysis_rules(file):\n",
    "    df = read_csv(file, na_filter=False)\n",
    "    rules = defaultdict(dict)\n",
    "    for _, r in df.iterrows():\n",
    "        if r.suffix not in rules[r.number]:\n",
    "            rules[r.number][r.suffix] = []\n",
    "        rules[r.number][r.suffix].append({'partofspeech': r.pos, 'form': r.form, 'ending':r.ending})\n",
    "    return rules\n",
    "\n",
    "rules = load_number_analysis_rules('results/number_analysis_rules.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the koondkorpus tokens find examples and support for the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830 good examples\n",
      "45995 numeric examples not covered by the rules\n",
      "token_count: 5000215\n",
      "not_alpha_count: 732035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>suffix</th>\n",
       "      <th>pos</th>\n",
       "      <th>form</th>\n",
       "      <th>ending</th>\n",
       "      <th>example</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>9918</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>teta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>neteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td>912a</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>lt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "      <td>8016-lt</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>neilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  number  suffix pos    form ending  example support\n",
       "0  ([1-9][0-9]*)?1[1-9]$           N       ?      0     9918    2016\n",
       "1  ([1-9][0-9]*)?1[1-9]$    teta   N   pl ab   teta                 \n",
       "2  ([1-9][0-9]*)?1[1-9]$     eta   N   pl ab   teta                 \n",
       "3  ([1-9][0-9]*)?1[1-9]$      ta   N   pl ab   teta                 \n",
       "4  ([1-9][0-9]*)?1[1-9]$  neteta   N   pl ab   teta                 \n",
       "5  ([1-9][0-9]*)?1[1-9]$   eteta   N   pl ab   teta                 \n",
       "6  ([1-9][0-9]*)?1[1-9]$       a   N   pl ab   teta     912a      49\n",
       "7  ([1-9][0-9]*)?1[1-9]$     ilt   N  pl abl    ilt                 \n",
       "8  ([1-9][0-9]*)?1[1-9]$      lt   N  pl abl    ilt  8016-lt      41\n",
       "9  ([1-9][0-9]*)?1[1-9]$   neilt   N  pl abl    ilt                 "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_count = 0\n",
    "not_alpha_count = 0\n",
    "\n",
    "numeric = re.compile('-?(\\d+\\.?)-?(\\D*)$')\n",
    "examples_good = {}\n",
    "examples_good_support = Counter()\n",
    "examples_bad = {}\n",
    "with open('../temp/wordlist', 'r', encoding='utf_8') as in_f:\n",
    "    for i, line in enumerate(in_f):\n",
    "        token_count += 1\n",
    "        token = line.strip()\n",
    "        if not token.isalpha():\n",
    "            not_alpha_count += 1\n",
    "            m = numeric.match(token)\n",
    "            if m:\n",
    "                good_token = False\n",
    "                number = m.group(1) \n",
    "                suffix = m.group(2)\n",
    "                for number_re in rules:\n",
    "                    if re.match(number_re, number):\n",
    "                        if suffix in rules[number_re]:\n",
    "                            good_token = True\n",
    "                            examples_good[(number_re, suffix)] = token\n",
    "                            examples_good_support[(number_re, suffix)] += 1\n",
    "                if not good_token:\n",
    "                    examples_bad[(number, suffix)] = token\n",
    "        if i % 10000 == 0:\n",
    "            clear_output()\n",
    "            display('{} {}'.format(i, token))\n",
    "                \n",
    "clear_output()\n",
    "\n",
    "print(len(examples_good), 'good examples')\n",
    "print(len(examples_bad),  'numeric examples not covered by the rules')\n",
    "print('token_count:', token_count)\n",
    "print('not_alpha_count:', not_alpha_count)\n",
    "\n",
    "df = read_csv('results/number_analysis_rules.csv', na_filter=False)\n",
    "example = []\n",
    "support = []\n",
    "for _, r in df.iterrows():\n",
    "    example.append(examples_good.get((r.number, r.suffix), ''))\n",
    "    support.append(examples_good_support.get((r.number, r.suffix), ''))\n",
    "df['example'] = example\n",
    "df['support'] = support\n",
    "\n",
    "df.to_csv('results/number_analysis_rules_with_examples.csv', index=False)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [results/number_analysis_rules_with_examples.csv](results/number_analysis_rules_with_examples.csv) for all examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some examples of the tokens that contain numbers but are not covered by the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980-eurose ('980', 'eurose')\n",
      "153hektarisel ('153', 'hektarisel')\n",
      "25protsendiga ('25', 'protsendiga')\n",
      "-273c ('273', 'c')\n",
      "91aastane ('91', 'aastane')\n",
      "300-punktilisele ('300', 'punktilisele')\n",
      "30-klapilist ('30', 'klapilist')\n",
      "80kiloste ('80', 'kiloste')\n",
      "82cm ('82', 'cm')\n",
      "15minutilises ('15', 'minutilises')\n",
      "1800-mehelise ('1800', 'mehelise')\n",
      "13kraadine ('13', 'kraadine')\n",
      "206cc ('206', 'cc')\n",
      "12-dollarilist ('12', 'dollarilist')\n",
      "165-kroonine ('165', 'kroonine')\n",
      "121-meetrise ('121', 'meetrise')\n",
      "9sentimeetrine ('9', 'sentimeetrine')\n",
      "607sekundit ('607', 'sekundit')\n",
      "30-liitrilise ('30', 'liitrilise')\n",
      "113jj ('113', 'jj')\n",
      "0-baasiline ('0', 'baasiline')\n",
      "65meetrine ('65', 'meetrine')\n",
      "71-kroonine ('71', 'kroonine')\n",
      "90Sr ('90', 'Sr')\n",
      "97protsendiline ('97', 'protsendiline')\n",
      "18-mehelised ('18', 'mehelised')\n",
      "716-k ('716', 'k')\n",
      "2Quickstarti ('2', 'Quickstarti')\n",
      "1-MCP-l ('1', 'MCP-l')\n",
      "3A ('3', 'A')\n",
      "6nnetu ('6', 'nnetu')\n",
      "50naelsterlingise ('50', 'naelsterlingise')\n",
      "6nnest ('6', 'nnest')\n",
      "051-le ('051', 'le')\n",
      "00817 ('00817', '')\n",
      "19-miljonilisest ('19', 'miljonilisest')\n",
      "40leheküljeliseks ('40', 'leheküljeliseks')\n",
      "20-partiiliseks ('20', 'partiiliseks')\n",
      "007. ('007.', '')\n",
      "35S ('35', 'S')\n",
      "2-Portland ('2', 'Portland')\n",
      "05151195 ('05151195', '')\n",
      "7600gs ('7600', 'gs')\n",
      "88-protsendilise ('88', 'protsendilise')\n",
      "25-miljonilise ('25', 'miljonilise')\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "for k, v in examples_bad.items():\n",
    "    if (random() < 0.001):\n",
    "        print(v, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze numeric tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': 's',\n",
       "  'form': 'sg in',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']},\n",
       " {'clitic': '',\n",
       "  'ending': '0',\n",
       "  'form': 'sg n',\n",
       "  'lemma': '11.',\n",
       "  'partofspeech': 'O',\n",
       "  'root': '11.',\n",
       "  'root_tokens': ['11.']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def analyze_number(token):\n",
    "    m = re.match('-?(\\d+\\.?)-?(\\D*)$', token)\n",
    "    if not m:\n",
    "        return []\n",
    "    m.group(0), \n",
    "    number = m.group(1)\n",
    "    ordinal_number = number.rstrip('.') + '.'\n",
    "    ending = m.group(2)\n",
    "    result = []\n",
    "    for number_re, analyses in rules.items():\n",
    "        if re.match(number_re, number):\n",
    "            for analysis in analyses[ending]:\n",
    "                if analysis['partofspeech'] == 'O':\n",
    "                    a = {'lemma':ordinal_number, 'root':ordinal_number, 'root_tokens':[ordinal_number], 'clitic':''}\n",
    "                else:\n",
    "                    a = {'lemma':number, 'root':number, 'root_tokens':[number], 'clitic':''}\n",
    "                a.update(analysis)\n",
    "                result.append(a)\n",
    "            break\n",
    "    return result\n",
    "\n",
    "analyze_number('11nes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': '0',\n",
       "  'form': '?',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_number('11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': 'iks',\n",
       "  'form': 'pl tr',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']},\n",
       " {'clitic': '',\n",
       "  'ending': 'iks',\n",
       "  'form': 'pl tr',\n",
       "  'lemma': '11.',\n",
       "  'partofspeech': 'O',\n",
       "  'root': '11.',\n",
       "  'root_tokens': ['11.']}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_number('11iks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roman numerals\n",
    "## From the koondkorpus tokens find examples of Roman numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper_case_roman_numeral_match = re.compile('(M*(CM)?(C?D)?C{0,3}(XC)?(X?L)?X{0,3}(IX)?(I?V)?I{0,3})(-(.*))?$').match\n",
    "lower_case_roman_numeral_match = re.compile('(m*(cm)?(c?d)?c{0,3}(xc)?(x?l)?x{0,3}(ix)?(i?v)?i{0,3})(-(.*))?$').match\n",
    "\n",
    "numbers = []\n",
    "simple_numbers = []\n",
    "with open('../temp/wordlist', 'r', encoding='utf_8') as in_f:\n",
    "    for i, line in enumerate(in_f):\n",
    "        token = line.strip()\n",
    "\n",
    "        m = upper_case_roman_numeral_match(token) or lower_case_roman_numeral_match(token)\n",
    "        if m:\n",
    "            number = m.group(1)\n",
    "            suffix = m.group(9)\n",
    "            if number:\n",
    "                if not suffix or suffix.isalpha() and (suffix.islower() or suffix.isupper()):\n",
    "                    numbers.append(token)\n",
    "                if token.isalpha():\n",
    "                    simple_numbers.append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Roman numerals in the koondkorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C, CC, CCC, CCCL, CCCXV, CCI, CCV, CCX, CCXII, CD, CDC, CDI, CDL, CDLXXXVIII, CDV, CDX, CI, CII, CIII, CIV, CIX, CL, CLI, CLII, CLV, CLX, CLXIV, CLXXXIX, CM, CMC, CMCI, CMD, CMI, CML, CMV, CMX, CV, CVII, CX, CXC, CXCV, CXII, CXIX, CXL, CXX, CXXIX, CXXVII, CXXX, D, DC, DCC, DCI, DCLXVI, DCX, DI, DII, DIII, DIV, DIX, DIXI, DL, DLV, DLX, DV, DVI, DX, DXC, I, II, III, IV, IVI, IX, IXI, IXIV, L, LI, LII, LIV, LIX, LV, LX, LXI, LXX, LXXIII, LXXVI, LXXX, LXXXIX, LXXXV, M, MC, MCC, MCD, MCI, MCL, MCM, MCMC, MCMXC, MCMXCII, MCMXCVI, MCMXCVII, MCMXIX, MCMXLIX, MCV, MCX, MD, MDC, MDCXXXI, MDCXXXII, MDI, MDL, MDV, MDX, MI, MII, MIV, MIX, MIXI, ML, MLI, MM, MMC, MMCCLXXXIX, MMD, MMI, MMII, MML, MMLV, MMM, MMMM, MMMMM, MMMMMM, MMMMMMMMMM, MMMMMMMMMMM, MMMMMMMMMMMMMMMM, MMX, MMXI, MV, MX, V, VI, VII, VIII, X, XC, XCVIII, XI, XII, XIII, XIV, XIX, XL, XLI, XLII, XLIII, XLVI, XV, XVI, XVII, XVIII, XX, XXI, XXII, XXIII, XXIV, XXIX, XXV, XXVI, XXVII, XXVIII, XXX, XXXI, XXXII, XXXIII, XXXIV, XXXIX, XXXV, XXXVI, XXXVII, XXXVIII, c, cc, ccc, ccx, cd, cdc, cdi, cdl, cdx, ci, cii, ciii, civ, cl, cli, cm, cmd, cmi, cv, cx, cxx, d, dc, dcc, dci, di, dii, div, divi, dix, dixi, dl, dli, dv, dvi, dx, i, ii, iii, iv, ivi, ix, ixi, l, li, lii, liv, livi, lv, lvi, lx, m, mc, mcd, mci, mcv, md, mdx, mi, mii, miv, mix, mixi, ml, mm, mmc, mmi, mml, mmm, mmmm, mmmmm, mmmmmm, mmmmmmm, mmmmmmmm, mmmmmmmmm, mmmmmmmmmm, mmmmmmmmmmm, mmmmmmmmmmmm, mmmmmmmmmmmmm, mmmmmmmmmmmmmmmmm, mmmmmmmmmmmmmmmmmmm, mmx, mv, mx, v, vi, vii, viii, x, xc, xi, xii, xiii, xiv, xix, xl, xli, xv, xvi, xvii, xviii, xx, xxi, xxii, xxiii, xxx, xxxi, xxxiv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(simple_numbers), 'tokens')\n",
    "', '.join(simple_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roman numerals with all sorts of suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5774 tokens. \n",
      "Some examples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C, C-alagruppi, C-grupp, C-kategooriat, C-korvist, C-näitaja, C-samba, C-terminali, C-viirusele, CC-, CD-WR, CD-draivid, CD-keskusega, CD-kopyst, CD-makke, CD-plaadidele, CD-pragu, CD-salvestuse, CD-toorik, CD-ümbristesse, CMD-J, CXII, D-d, D-keelekategooria, D-nelikus, D-suunal, D-vitamiinivarude, DL-määramismeetodite, I, I-grupi, I-punktina, II-e, III-l, IV-st, L-e, L-kujuliselt, L-valiin, M-F, M-id, M-lle, M-päevas, M-viirusega, MD-ga, ML-SS, MM-alagruppide, MM-esitusi, MM-finaalis, MM-hooaeg, MM-kalender, MM-koha, MM-krossidel, MM-linna, MM-medali, MM-nimetusest, MM-pretendendi, MM-pääsunormi, MM-romaanis, MM-sõidust, MM-tiitlil, MM-tsüklile, MM-valikkohtumistes, MM-valikturniirist, MM-võistlusteks, MMM-s, MX, V-ga, V-linkide, V-playeriga, V-universaal, VII-VIII, X-TABEL, X-failid, X-kastiga, X-lehe, X-pressi, X-tabelis, X-windows, XIII-t, XVI-XIX, XXX-large, c-kvark, cd-boxid, cd-kirjutajasse, cd-plaatide, cd-seadmetega, cm-, d-ebüütkogu, d-ta, dl-le, i-bändide, i-hääletust, i-kirjele, i-laadset, i-mees, i-node, i-punkte, i-sid, i-telefoniga, i-vaimud, ii-al, l-virumaalt, lii-tiumioonakude, m-kaubandusest, m-oste, m-uudised, mi-mina, mix-plaatide, mmm-mmmidest, v-max, vii-binud, x-asi, x-id, x-kujulise, x-planeedi, x-telg, xvii-xviii'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(numbers), 'tokens. \\nSome examples:')\n",
    "', '.join(numbers[::50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
