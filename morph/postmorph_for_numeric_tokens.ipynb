{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postmorph analysis for numeric tokens\n",
    "\n",
    "## Create a rules file for analyzing numeric tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5873 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>suffix</th>\n",
       "      <th>pos</th>\n",
       "      <th>form</th>\n",
       "      <th>ending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3674</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>teta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>neteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>t</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>lt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>neilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     number  suffix pos    form ending\n",
       "3564  ([1-9][0-9]*)?1[1-9]$           N       ?      0\n",
       "3569  ([1-9][0-9]*)?1[1-9]$      ta   N   pl ab   teta\n",
       "3603  ([1-9][0-9]*)?1[1-9]$     eta   N   pl ab   teta\n",
       "3674  ([1-9][0-9]*)?1[1-9]$   eteta   N   pl ab   teta\n",
       "3705  ([1-9][0-9]*)?1[1-9]$       a   N   pl ab   teta\n",
       "3820  ([1-9][0-9]*)?1[1-9]$    teta   N   pl ab   teta\n",
       "3834  ([1-9][0-9]*)?1[1-9]$  neteta   N   pl ab   teta\n",
       "3628  ([1-9][0-9]*)?1[1-9]$       t   N  pl abl    ilt\n",
       "3789  ([1-9][0-9]*)?1[1-9]$      lt   N  pl abl    ilt\n",
       "3974  ([1-9][0-9]*)?1[1-9]$   neilt   N  pl abl    ilt"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from estnltk.vabamorf.morf import synthesize, analyze\n",
    "from collections import defaultdict\n",
    "\n",
    "number_words = {\n",
    "                '0$': {'words': ('null', 'nullis'),\n",
    "                       'roots': ('null',)},\n",
    "                '1$|[2-9]1$|([1-9][0-9]*[02-9])1$': {'words': ('üks', 'esimene'),\n",
    "                       'roots': ('üh', 'esime')},\n",
    "                '2$|[2-9]2$|([1-9][0-9]*[02-9])2$': {'words': ('kaks', 'teine'),\n",
    "                       'roots': ('kah', 'teis')},\n",
    "                '3$|[2-9]3$|([1-9][0-9]*[02-9])3$': {'words': ('kolm', 'kolmas'),\n",
    "                       'roots': ('kolma', 'kolm')},\n",
    "                '4$|[2-9]4$|([1-9][0-9]*[02-9])4$': {'words': ('neli', 'neljas'),\n",
    "                       'roots': ('nel',)},\n",
    "                '5$|[2-9]5$|([1-9][0-9]*[02-9])5$': {'words': ('viis', 'viies'),\n",
    "                       'roots': ('vii',)},\n",
    "                '6$|[2-9]6$|([1-9][0-9]*[02-9])6$': {'words': ('kuus', 'kuues'),\n",
    "                       'roots': ('kuu',)},\n",
    "                '7$|[2-9]7$|([1-9][0-9]*[02-9])7$': {'words': ('seitse', 'seitsmes'),\n",
    "                       'roots': ('seits',)},\n",
    "                '8$|[2-9]8$|([1-9][0-9]*[02-9])8$': {'words': ('kaheksa', 'kaheksas'),\n",
    "                       'roots': ('kaheks',)},\n",
    "                '9$|[2-9]9$|([1-9][0-9]*[02-9])9$': {'words': ('üheksa', 'üheksas'),\n",
    "                       'roots': ('üheks',)},\n",
    "                '([1-9][0-9]*)?1[1-9]$': {'words': ('kolmteist', 'kolmeteistkümnes'),\n",
    "                       'roots': ('kolmeteistküm',)},\n",
    "                '([1-9][0-9]*)?[1-9]0$': {'words': ('kolmkümmend', 'kolmekümnes'),\n",
    "                       'roots': ('kolmeküm',)},\n",
    "                '([1-9][0-9]*)?[1-9]00$': {'words': ('sada', 'sajas'),\n",
    "                       'roots': ('sad', 'sa')},\n",
    "                '([1-9][0-9]*)?[1-9]0{3,5}$': {'words': ('tuhat', 'tuhandes'),\n",
    "                       'roots': ('tuhan','tuha')},\n",
    "                '([1-9][0-9]*)?[1-9]0{6,8}(0{6}0*)?$': {'words': ('miljon', 'miljones'),\n",
    "                                               'roots': ('miljon',)},\n",
    "                '([1-9][0-9]*)?[1-9]0{9,11}$': {'words': ('miljard', 'miljardes'),\n",
    "                       'roots': ('miljard',)}\n",
    "               }\n",
    "\n",
    "forms =  ['sg n', 'pl n', 'sg g', 'pl g', 'sg p', 'pl p', 'sg ill', 'pl ill', 'adt', 'sg in', 'pl in',\n",
    "          'sg el', 'pl el', 'sg all', 'pl all', 'sg ad', 'pl ad', 'sg abl', 'pl abl', 'sg tr',\n",
    "          'pl tr', 'sg ter', 'pl ter', 'sg es', 'pl es', 'sg ab', 'pl ab', 'sg kom', 'pl kom']\n",
    "\n",
    "for number, data in number_words.items():\n",
    "    data['analyses'] = {}\n",
    "    for form in forms:\n",
    "        for number_word in data['words']:\n",
    "            for synt in synthesize(number_word, form):\n",
    "                analysis = analyze([synt], disambiguate=False, guess=False, propername=False)[0]['analysis']\n",
    "                for a in analysis:\n",
    "                    if a['partofspeech'] in {'N', 'O'}:\n",
    "                        data['analyses'].setdefault(synt, set()).add((a['partofspeech'], a['form'], a['ending']))\n",
    "\n",
    "for number, data in number_words.items():\n",
    "    data['suffixes'] = {}\n",
    "    for word_form in data['analyses']:\n",
    "        for root in data['roots']:\n",
    "            ending = word_form.partition(root)[-1]\n",
    "            if ending:\n",
    "                for i in range(len(ending)):\n",
    "                    data['suffixes'][ending[i:]] = set()\n",
    "                break\n",
    "    for ending, analyses in data['suffixes'].items():\n",
    "        for word_form, a in data['analyses'].items():\n",
    "            if word_form.endswith(ending):\n",
    "                for pos, form, suffix in a:\n",
    "                    if pos!='N' or form!='sg n':\n",
    "                        analyses.add((pos, form, suffix))\n",
    "    data['suffixes'][''] = {('N', '?', '0')}\n",
    "    \n",
    "    \n",
    "table = []\n",
    "for number, data in number_words.items():\n",
    "    for ending, analyses in data['suffixes'].items():\n",
    "        for pos, form, normal_ending in analyses:\n",
    "            table.append({\n",
    "                        'number': number,\n",
    "                        'suffix': ending,\n",
    "                        'pos': pos,\n",
    "                        'form': form,\n",
    "                        'ending': normal_ending\n",
    "            })\n",
    "\n",
    "df = DataFrame.from_records(table, columns=['number', 'suffix', 'pos', 'form', 'ending'])\n",
    "df = df.sort_values(['number', 'pos', 'form', 'ending'])\n",
    "\n",
    "df.to_csv('results/number_analysis_rules.csv', index=False)\n",
    "\n",
    "print(len(df), 'lines')\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rules file [results/number_analysis_rules.csv](results/number_analysis_rules.csv) **pos**, **form** and **ending** cells contain the morphological analysis for the tokens that match **number** with **suffix**.\n",
    "\n",
    "## Load the rules from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "def load_number_analysis_rules(file):\n",
    "    df = read_csv(file, na_filter=False)\n",
    "    rules = defaultdict(dict)\n",
    "    for _, r in df.iterrows():\n",
    "        if r.suffix not in rules[r.number]:\n",
    "            rules[r.number][r.suffix] = []\n",
    "        rules[r.number][r.suffix].append({'partofspeech': r.pos, 'form': r.form, 'ending':r.ending})\n",
    "    return rules\n",
    "\n",
    "rules = load_number_analysis_rules('results/number_analysis_rules.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze numeric tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': 'teta',\n",
       "  'form': 'pl ab',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def analyze_number(token):\n",
    "    m = re.match('-?(\\d+)-?(\\D*)', token)\n",
    "    if not m:\n",
    "        return []\n",
    "    m.group(0), \n",
    "    number = m.group(1) \n",
    "    ending = m.group(2)\n",
    "    result = []\n",
    "    for number_re, analyses in rules.items():\n",
    "        if re.match(number_re, number):\n",
    "            for analysis in analyses[ending]:\n",
    "                a = {'lemma':number, 'root':number, 'root_tokens':[number], 'clitic':''}\n",
    "                a.update(analysis)\n",
    "                result.append(a)\n",
    "    return result\n",
    "\n",
    "analyze_number('11eteta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': 'dena',\n",
       "  'form': 'pl es',\n",
       "  'lemma': '1',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '1',\n",
       "  'root_tokens': ['1']},\n",
       " {'clitic': '',\n",
       "  'ending': 'na',\n",
       "  'form': 'sg es',\n",
       "  'lemma': '1',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '1',\n",
       "  'root_tokens': ['1']},\n",
       " {'clitic': '',\n",
       "  'ending': 'tena',\n",
       "  'form': 'pl es',\n",
       "  'lemma': '1',\n",
       "  'partofspeech': 'O',\n",
       "  'root': '1',\n",
       "  'root_tokens': ['1']},\n",
       " {'clitic': '',\n",
       "  'ending': 'na',\n",
       "  'form': 'sg es',\n",
       "  'lemma': '1',\n",
       "  'partofspeech': 'O',\n",
       "  'root': '1',\n",
       "  'root_tokens': ['1']}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_number('1na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': 'iks',\n",
       "  'form': 'pl tr',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']},\n",
       " {'clitic': '',\n",
       "  'ending': 'iks',\n",
       "  'form': 'pl tr',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'O',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_number('11iks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
