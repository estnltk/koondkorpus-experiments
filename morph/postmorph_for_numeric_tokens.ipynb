{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from estnltk.vabamorf.morf import synthesize, analyze\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postmorph analysis for numeric tokens\n",
    "\n",
    "## Create a rules file for analyzing numeric tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5873 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>suffix</th>\n",
       "      <th>pos</th>\n",
       "      <th>form</th>\n",
       "      <th>ending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>neteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>teta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>lt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     number  suffix pos    form ending\n",
       "3901  ([1-9][0-9]*)?1[1-9]$           N       ?      0\n",
       "3799  ([1-9][0-9]*)?1[1-9]$     eta   N   pl ab   teta\n",
       "3812  ([1-9][0-9]*)?1[1-9]$      ta   N   pl ab   teta\n",
       "3920  ([1-9][0-9]*)?1[1-9]$  neteta   N   pl ab   teta\n",
       "3976  ([1-9][0-9]*)?1[1-9]$    teta   N   pl ab   teta\n",
       "3984  ([1-9][0-9]*)?1[1-9]$   eteta   N   pl ab   teta\n",
       "4144  ([1-9][0-9]*)?1[1-9]$       a   N   pl ab   teta\n",
       "3956  ([1-9][0-9]*)?1[1-9]$      lt   N  pl abl    ilt\n",
       "3964  ([1-9][0-9]*)?1[1-9]$     ilt   N  pl abl    ilt\n",
       "3986  ([1-9][0-9]*)?1[1-9]$    eilt   N  pl abl    ilt"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_words = {\n",
    "                '0$': {'words': ('null', 'nullis'),\n",
    "                       'roots': ('null',)},\n",
    "                '1$|[2-9]1$|([1-9][0-9]*[02-9])1$': {'words': ('üks', 'esimene'),\n",
    "                       'roots': ('üh', 'esime')},\n",
    "                '2$|[2-9]2$|([1-9][0-9]*[02-9])2$': {'words': ('kaks', 'teine'),\n",
    "                       'roots': ('kah', 'teis')},\n",
    "                '3$|[2-9]3$|([1-9][0-9]*[02-9])3$': {'words': ('kolm', 'kolmas'),\n",
    "                       'roots': ('kolma', 'kolm')},\n",
    "                '4$|[2-9]4$|([1-9][0-9]*[02-9])4$': {'words': ('neli', 'neljas'),\n",
    "                       'roots': ('nel',)},\n",
    "                '5$|[2-9]5$|([1-9][0-9]*[02-9])5$': {'words': ('viis', 'viies'),\n",
    "                       'roots': ('vii',)},\n",
    "                '6$|[2-9]6$|([1-9][0-9]*[02-9])6$': {'words': ('kuus', 'kuues'),\n",
    "                       'roots': ('kuu',)},\n",
    "                '7$|[2-9]7$|([1-9][0-9]*[02-9])7$': {'words': ('seitse', 'seitsmes'),\n",
    "                       'roots': ('seits',)},\n",
    "                '8$|[2-9]8$|([1-9][0-9]*[02-9])8$': {'words': ('kaheksa', 'kaheksas'),\n",
    "                       'roots': ('kaheks',)},\n",
    "                '9$|[2-9]9$|([1-9][0-9]*[02-9])9$': {'words': ('üheksa', 'üheksas'),\n",
    "                       'roots': ('üheks',)},\n",
    "                '([1-9][0-9]*)?1[1-9]$': {'words': ('kolmteist', 'kolmeteistkümnes'),\n",
    "                       'roots': ('kolmeteistküm',)},\n",
    "                '([1-9][0-9]*)?[1-9]0$': {'words': ('kolmkümmend', 'kolmekümnes'),\n",
    "                       'roots': ('kolmeküm',)},\n",
    "                '([1-9][0-9]*)?[1-9]00$': {'words': ('sada', 'sajas'),\n",
    "                       'roots': ('sad', 'sa')},\n",
    "                '([1-9][0-9]*)?[1-9]0{3,5}$': {'words': ('tuhat', 'tuhandes'),\n",
    "                       'roots': ('tuhan','tuha')},\n",
    "                '([1-9][0-9]*)?[1-9]0{6,8}(0{6}0*)?$': {'words': ('miljon', 'miljones'),\n",
    "                                               'roots': ('miljon',)},\n",
    "                '([1-9][0-9]*)?[1-9]0{9,11}$': {'words': ('miljard', 'miljardes'),\n",
    "                       'roots': ('miljard',)}\n",
    "               }\n",
    "\n",
    "forms =  ['sg n', 'pl n', 'sg g', 'pl g', 'sg p', 'pl p', 'sg ill', 'pl ill', 'adt', 'sg in', 'pl in',\n",
    "          'sg el', 'pl el', 'sg all', 'pl all', 'sg ad', 'pl ad', 'sg abl', 'pl abl', 'sg tr',\n",
    "          'pl tr', 'sg ter', 'pl ter', 'sg es', 'pl es', 'sg ab', 'pl ab', 'sg kom', 'pl kom']\n",
    "\n",
    "for number, data in number_words.items():\n",
    "    data['analyses'] = {}\n",
    "    for form in forms:\n",
    "        for number_word in data['words']:\n",
    "            for synt in synthesize(number_word, form):\n",
    "                analysis = analyze([synt], disambiguate=False, guess=False, propername=False)[0]['analysis']\n",
    "                for a in analysis:\n",
    "                    if a['partofspeech'] in {'N', 'O'}:\n",
    "                        data['analyses'].setdefault(synt, set()).add((a['partofspeech'], a['form'], a['ending']))\n",
    "\n",
    "for number, data in number_words.items():\n",
    "    data['suffixes'] = {}\n",
    "    for word_form in data['analyses']:\n",
    "        for root in data['roots']:\n",
    "            ending = word_form.partition(root)[-1]\n",
    "            if ending:\n",
    "                for i in range(len(ending)):\n",
    "                    data['suffixes'][ending[i:]] = set()\n",
    "                break\n",
    "    for ending, analyses in data['suffixes'].items():\n",
    "        for word_form, a in data['analyses'].items():\n",
    "            if word_form.endswith(ending):\n",
    "                for pos, form, suffix in a:\n",
    "                    if pos!='N' or form!='sg n':\n",
    "                        analyses.add((pos, form, suffix))\n",
    "    data['suffixes'][''] = {('N', '?', '0')}\n",
    "    \n",
    "    \n",
    "table = []\n",
    "for number, data in number_words.items():\n",
    "    for ending, analyses in data['suffixes'].items():\n",
    "        for pos, form, normal_ending in analyses:\n",
    "            table.append({\n",
    "                        'number': number,\n",
    "                        'suffix': ending,\n",
    "                        'pos': pos,\n",
    "                        'form': form,\n",
    "                        'ending': normal_ending\n",
    "            })\n",
    "\n",
    "df = DataFrame.from_records(table, columns=['number', 'suffix', 'pos', 'form', 'ending'])\n",
    "df = df.sort_values(['number', 'pos', 'form', 'ending'])\n",
    "\n",
    "df.to_csv('results/number_analysis_rules.csv', index=False)\n",
    "\n",
    "print(len(df), 'lines')\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rules file [results/number_analysis_rules.csv](results/number_analysis_rules.csv) **pos**, **form** and **ending** cells contain the morphological analysis for the tokens that match **number** with **suffix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the rules from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_number_analysis_rules(file):\n",
    "    df = read_csv(file, na_filter=False)\n",
    "    rules = defaultdict(dict)\n",
    "    for _, r in df.iterrows():\n",
    "        if r.suffix not in rules[r.number]:\n",
    "            rules[r.number][r.suffix] = []\n",
    "        rules[r.number][r.suffix].append({'partofspeech': r.pos, 'form': r.form, 'ending':r.ending})\n",
    "    return rules\n",
    "\n",
    "rules = load_number_analysis_rules('results/number_analysis_rules.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the koondkorpus tokens find examples and support for the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697 good examples\n",
      "50873 numeric examples not covered by the rules\n",
      "token_count: 5000215\n",
      "not_alpha_count: 732035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>suffix</th>\n",
       "      <th>pos</th>\n",
       "      <th>form</th>\n",
       "      <th>ending</th>\n",
       "      <th>example</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>9918</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>neteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>teta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eteta</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>a</td>\n",
       "      <td>N</td>\n",
       "      <td>pl ab</td>\n",
       "      <td>teta</td>\n",
       "      <td>912a</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>lt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "      <td>8016-lt</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>ilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([1-9][0-9]*)?1[1-9]$</td>\n",
       "      <td>eilt</td>\n",
       "      <td>N</td>\n",
       "      <td>pl abl</td>\n",
       "      <td>ilt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  number  suffix pos    form ending  example support\n",
       "0  ([1-9][0-9]*)?1[1-9]$           N       ?      0     9918    2016\n",
       "1  ([1-9][0-9]*)?1[1-9]$     eta   N   pl ab   teta                 \n",
       "2  ([1-9][0-9]*)?1[1-9]$      ta   N   pl ab   teta                 \n",
       "3  ([1-9][0-9]*)?1[1-9]$  neteta   N   pl ab   teta                 \n",
       "4  ([1-9][0-9]*)?1[1-9]$    teta   N   pl ab   teta                 \n",
       "5  ([1-9][0-9]*)?1[1-9]$   eteta   N   pl ab   teta                 \n",
       "6  ([1-9][0-9]*)?1[1-9]$       a   N   pl ab   teta     912a      49\n",
       "7  ([1-9][0-9]*)?1[1-9]$      lt   N  pl abl    ilt  8016-lt      41\n",
       "8  ([1-9][0-9]*)?1[1-9]$     ilt   N  pl abl    ilt                 \n",
       "9  ([1-9][0-9]*)?1[1-9]$    eilt   N  pl abl    ilt                 "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_count = 0\n",
    "not_alpha_count = 0\n",
    "\n",
    "numeric = re.compile('-?(\\d+)-?(\\D*)$')\n",
    "examples_good = {}\n",
    "examples_good_support = Counter()\n",
    "examples_bad = {}\n",
    "with open('../temp/wordlist', 'r', encoding='utf_8') as in_f:\n",
    "    for i, line in enumerate(in_f):\n",
    "        token_count += 1\n",
    "        token = line.strip()\n",
    "        if not token.isalpha():\n",
    "            not_alpha_count += 1\n",
    "            m = numeric.match(token)\n",
    "            if m:\n",
    "                good_token = False\n",
    "                number = m.group(1) \n",
    "                suffix = m.group(2)\n",
    "                for number_re in rules:\n",
    "                    if re.match(number_re, number):\n",
    "                        if suffix in rules[number_re]:\n",
    "                            good_token = True\n",
    "                            examples_good[(number_re, suffix)] = token\n",
    "                            examples_good_support[(number_re, suffix)] += 1\n",
    "                if not good_token:\n",
    "                    examples_bad[(number, suffix)] = token\n",
    "        if i % 10000 == 0:\n",
    "            clear_output()\n",
    "            display('{} {}'.format(i, token))\n",
    "                \n",
    "clear_output()\n",
    "\n",
    "print(len(examples_good), 'good examples')\n",
    "print(len(examples_bad),  'numeric examples not covered by the rules')\n",
    "print('token_count:', token_count)\n",
    "print('not_alpha_count:', not_alpha_count)\n",
    "\n",
    "df = read_csv('results/number_analysis_rules.csv', na_filter=False)\n",
    "example = []\n",
    "support = []\n",
    "for _, r in df.iterrows():\n",
    "    example.append(examples_good.get((r.number, r.suffix), ''))\n",
    "    support.append(examples_good_support.get((r.number, r.suffix), ''))\n",
    "df['example'] = example\n",
    "df['support'] = support\n",
    "\n",
    "df.to_csv('results/number_analysis_rules_with_examples.csv', index=False)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [results/number_analysis_rules_with_examples.csv](results/number_analysis_rules_with_examples.csv) for all examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some examples of the tokens that contain numbers but are not covered by the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2075kroonisest ('2075', 'kroonisest')\n",
      "105dC ('105', 'dC')\n",
      "90b ('90', 'b')\n",
      "13-le. ('13', 'le.')\n",
      "5-astmelisel ('5', 'astmelisel')\n",
      "6-astmeline ('6', 'astmeline')\n",
      "07922 ('07922', '')\n",
      "2027. ('2027', '.')\n",
      "000ga ('000', 'ga')\n",
      "46m ('46', 'm')\n",
      "18000EEK ('18000', 'EEK')\n",
      "732708. ('732708', '.')\n",
      "8800punktise ('8800', 'punktise')\n",
      "18-Martin ('18', 'Martin')\n",
      "160-sentimeetriste ('160', 'sentimeetriste')\n",
      "42-seks ('42', 'seks')\n",
      "967. ('967', '.')\n",
      "1800mAh ('1800', 'mAh')\n",
      "16biti ('16', 'biti')\n",
      "30minti ('30', 'minti')\n",
      "1kl ('1', 'kl')\n",
      "37aastne ('37', 'aastne')\n",
      "400-kroonilisel ('400', 'kroonilisel')\n",
      "64-ruutmeetrine ('64', 'ruutmeetrine')\n",
      "17lk ('17', 'lk')\n",
      "90-kilost ('90', 'kilost')\n",
      "4220. ('4220', '.')\n",
      "60-dollarise ('60', 'dollarise')\n",
      "0-režiim ('0', 'režiim')\n",
      "14aastaseid ('14', 'aastaseid')\n",
      "880-ruutmeetrises ('880', 'ruutmeetrises')\n",
      "16-sekundilist ('16', 'sekundilist')\n",
      "23PL ('23', 'PL')\n",
      "14-Vicente ('14', 'Vicente')\n",
      "6676. ('6676', '.')\n",
      "5199. ('5199', '.')\n",
      "18-pealisest ('18', 'pealisest')\n",
      "50-stele ('50', 'stele')\n",
      "9-bitine ('9', 'bitine')\n",
      "03037993 ('03037993', '')\n",
      "220kilosest ('220', 'kilosest')\n",
      "30-mehelises ('30', 'mehelises')\n",
      "6404267. ('6404267', '.')\n",
      "3vul ('3', 'vul')\n",
      "2ravätmine ('2', 'ravätmine')\n",
      "8137m² ('8137', 'm²')\n",
      "120ruutmeetrisele ('120', 'ruutmeetrisele')\n",
      "17-kuuse ('17', 'kuuse')\n",
      "3BJ ('3', 'BJ')\n",
      "1400-kroonine ('1400', 'kroonine')\n",
      "150-aastasest ('150', 'aastasest')\n",
      "450Eesti ('450', 'Eesti')\n",
      "36kaadrisest ('36', 'kaadrisest')\n",
      "15-punktises ('15', 'punktises')\n",
      "500krooniste ('500', 'krooniste')\n",
      "310-tüüpi ('310', 'tüüpi')\n",
      "13-realine ('13', 'realine')\n",
      "133-kilose ('133', 'kilose')\n",
      "9600pro-del ('9600', 'pro-del')\n",
      "10140. ('10140', '.')\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "for k, v in examples_bad.items():\n",
    "    if (random() < 0.001):\n",
    "        print(v, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze numeric tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': 'teta',\n",
       "  'form': 'pl ab',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def analyze_number(token):\n",
    "    m = re.match('-?(\\d+)-?(\\D*)$', token)\n",
    "    if not m:\n",
    "        return []\n",
    "    m.group(0), \n",
    "    number = m.group(1) \n",
    "    ending = m.group(2)\n",
    "    result = []\n",
    "    for number_re, analyses in rules.items():\n",
    "        if re.match(number_re, number):\n",
    "            for analysis in analyses[ending]:\n",
    "                a = {'lemma':number, 'root':number, 'root_tokens':[number], 'clitic':''}\n",
    "                a.update(analysis)\n",
    "                result.append(a)\n",
    "    return result\n",
    "\n",
    "analyze_number('11eteta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': '0',\n",
       "  'form': '?',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_number('11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'clitic': '',\n",
       "  'ending': 'iks',\n",
       "  'form': 'pl tr',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'N',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']},\n",
       " {'clitic': '',\n",
       "  'ending': 'iks',\n",
       "  'form': 'pl tr',\n",
       "  'lemma': '11',\n",
       "  'partofspeech': 'O',\n",
       "  'root': '11',\n",
       "  'root_tokens': ['11']}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_number('11iks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
