{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "from estnltk.validators.word_validator import Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronouns\n",
    "Find all tokens that either `Vabamorf` or `Token.is_pronoun` thinks is pronoun. Write the results into csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6260 pronoun-like tokens written to the file results/pronouns.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>vabamorf</th>\n",
       "      <th>is_pronoun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-END-</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-Esimene</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Esimese</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Esimeses</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Esimest</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-Iga</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-Igal</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-Igalt</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-Ise</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-Keda</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token vabamorf is_pronoun\n",
       "0      -END-     True       True\n",
       "1   -Esimene     True       True\n",
       "2   -Esimese     True       True\n",
       "3  -Esimeses     True       True\n",
       "4   -Esimest     True       True\n",
       "5       -Iga     True       True\n",
       "6      -Igal     True       True\n",
       "7     -Igalt     True       True\n",
       "8       -Ise     True       True\n",
       "9      -Keda     True       True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronouns = []\n",
    "with open('../temp/wordlist') as in_f:\n",
    "    for i, line in enumerate(in_f):\n",
    "        token = Token(line.strip())\n",
    "        if 'P' in token.part_of_speeches or token.is_pronoun:\n",
    "            pronouns.append({'token': token, \n",
    "                             'vabamorf': 'P' in token.part_of_speeches,\n",
    "                             'is_pronoun': token.is_pronoun})\n",
    "            if len(pronouns) % 501 == 1:\n",
    "                clear_output()\n",
    "                display('{} {}'.format(i, token))\n",
    "\n",
    "            \n",
    "df = pandas.DataFrame.from_records(pronouns, columns=['token', 'vabamorf', 'is_pronoun'])\n",
    "out_file = 'results/pronouns.csv'\n",
    "df.to_csv(out_file, index=False)\n",
    "clear_output()\n",
    "print(len(pronouns), 'pronoun-like tokens written to the file', out_file)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting tokens\n",
    "Find all tokens\n",
    " - that contain a hyphen '`-`',\n",
    " - that are words if hyphens removed,\n",
    " - where all hyphen-separated parts are words,\n",
    " - that contain a hyphen-separated part that consists of 2 or 3 letters and\n",
    " - that are not pronouns.\n",
    " \n",
    " Being a word is defined by `Token.is_word` and being a pronoun is defined by `Token.is_pronoun`.\n",
    " \n",
    " Write the results into file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12204 interesting tokens written to the file results/interesting_tokens.txt\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "with open('../temp/wordlist', 'r', encoding='utf_8') as in_f:\n",
    "    for i, line in enumerate(in_f):\n",
    "        if '-' in line:\n",
    "            token = Token(line.strip())\n",
    "            parts = token.split('-')\n",
    "            if not any(1<len(part)<4 and part.isalpha() for part in parts):\n",
    "                continue\n",
    "            if not token.replace('-', '').is_word:\n",
    "                continue\n",
    "            if not all(part.is_word for part in parts):\n",
    "                continue\n",
    "            if token.is_pronoun:\n",
    "                continue\n",
    "            result.append(token)\n",
    "            if len(result) % 501 == 1:\n",
    "                clear_output()\n",
    "                display('{} {}'.format(i, token))\n",
    "clear_output()\n",
    "out_file = 'results/interesting_tokens.txt'\n",
    "with open('results/interesting_tokens.txt', 'w', encoding='utf_8') as out_f:\n",
    "    for token in result:\n",
    "        print(token, file=out_f)\n",
    "\n",
    "print(len(result), 'interesting tokens written to the file', out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
